# ðŸŽ¶ Portuguese Radio Analysis

Ever wondered what songs dominate Portuguese radio? This project scrapes and analyzes music data from 4 major Portuguese radio stations (CidadeFM, RFM, MegaHits and RÃ¡dio Comercial), providing a deep dive into whatâ€™s being played, from trending hits to long-standing classics. Using **web scraping, machine learning, and interactive visualizations**, this project helps uncover trends in music preferences across stations.

The project consists of two main parts:

1. **ETL Process**: Scrapes and processes data from radio websites and integrates additional information from APIs.
2. **Streamlit Dashboard**: Visualizes the analyzed data in an interactive and user-friendly web application.

---

## ðŸ› ï¸ Features

### ETL Process

- **Data Scraping**: Scrapes real-time playlists from four Portuguese radio stations, capturing song titles, artists, and playtimes.
- **API Integration**: Enhances music metadata by integrating with:
  - ðŸŽµ **Spotify**: Track popularity & metadata.
  - ðŸ“ **Genius**: Lyrics for sentiment analysis.
  - ðŸ“– **Wikipedia & MusicBrainz**: Artist biographies & song history.
- **Lyrics Sentiment Analysis**: Uses **Machine Learning (ML)** models to detect emotions like joy, sadness, and anger.
- **Data Transformation**: Standardizes and cleans data for seamless analysis and visualization.
- **Optimized Performance**:
  - ðŸš€ **Asyncio** for concurrent API requests, improving speed.
  - âš¡ **Polars** for fast and memory-efficient DataFrame operations.


### Streamlit Dashboard

- **Overview Comparison**: See how four major Portuguese radio stations stack up:
  - ðŸŽµ **Top Artists & Songs**: Most played tracks and their total air time.
  - ðŸŒ **Language & Origin**: Breakdown of song languages and artist nationalities.
  - ðŸ“… **Decades & Genres**: What eras dominate the airwaves?
  - ðŸ˜Š **Lyrics & Emotions**: Sentiment analysis of the lyrics being played.
- **Deep Dive**: Focuses on one radio station and compares it to others.
- **Self-Service Exploration**: Allows users to explore and extract data for custom analysis.
- **Interactive Visualizations**: Provides charts and filters for dynamic insights.

The dashboard is structured as follows:
- `overview_comparison.py`: Broad comparison across multiple radios.
- `radio_deep_dive.py`: Detailed insights into a selected radio station.
- `self_service.py`: Free exploration and data export.

Each page uses helper modules from `dashboard/utils/` for data processing, filtering, and visualization. The main entry point (`app.py`) initializes the dashboard and integrates all pages seamlessly.


---

## ðŸ—‚ï¸ Project Structure

The project is divided into two main parts:
- ðŸ“‚ **Dashboard Files** (Streamlit-based visualization)
- ðŸ“‚ **ETL Pipeline Files** (Data Scraping, Processing & API Enrichment)

```plaintext
portuguese-radio-analysis/

ðŸ“‚ Dashboard Files
â”œâ”€â”€ dashboard/                       # Streamlit dashboard files
â”‚   â”œâ”€â”€ app.py                       # Main entry point for the Streamlit app
â”‚   â”œâ”€â”€ pages/                       # Code for each dashboard page
â”‚   â”œâ”€â”€ spec/                        # Self-Service page specification file
â”‚   â”œâ”€â”€ logo/                        # Logos used in the dashboard
â”‚   â””â”€â”€ utils/                       # Helper modules for plotting and data handling
â”‚       â”œâ”€â”€ calculations.py          # Contains calculation logic for the dashboard
â”‚       â”œâ”€â”€ filters.py               # Filtering functionality for plots
â”‚       â”œâ”€â”€ helper.py                # Helper functions
â”‚       â””â”€â”€ storage.py               # Handles data loading for the dashboard

ðŸ“‚ ETL Pipeline Files
â”œâ”€â”€ data_extract/                    # ETL process files
â”‚   â”œâ”€â”€ logs/                        # Logging for the ETL process
â”‚   â”œâ”€â”€ asynchronous_spotify_api.py  # Spotify API integration with asyncio
â”‚   â”œâ”€â”€ config_manager.py            # Configuration manager
â”‚   â”œâ”€â”€ data_storage.py              # Handles data storage and loading
â”‚   â”œâ”€â”€ genius.api.py                # Genius Lyrics API integration
â”‚   â”œâ”€â”€ logger.py                    # Logging utilities
â”‚   â”œâ”€â”€ lyrics.py                    # Lyrics sentiment analysis
â”‚   â”œâ”€â”€ musicbrainz_api.py           # MusicBrainz API integration
â”‚   â”œâ”€â”€ radio_music_etl.py           # Main ETL pipeline
â”‚   â”œâ”€â”€ radio_scraper.py             # Web scraping logic
â”‚   â””â”€â”€ wikipedia_api.py             # Wikipedia API integration

ðŸ“‚ Documentation
â”œâ”€â”€ documentation/                   # Additional documentation and metric explanations
â”‚   â””â”€â”€ spotify_metrics.md           # Documentation on Spotify metrics

ðŸ“‚ Data Folders
â”œâ”€â”€ extract_folder/                  # Raw data extracted from scrapers and APIs
â”œâ”€â”€ transform_folder/                # Transformed and cleaned data

ðŸ“‚ Configuration
â”œâ”€â”€ .env.example                     # Example environment variables file
â”œâ”€â”€ config.json                      # File paths and scraper configurations
â”œâ”€â”€ schema.json                      # Data schema definitions

ðŸ“‚ Environment and Dependencies
â”œâ”€â”€ venv/                            # Python virtual environment (local)
â”œâ”€â”€ setup.py                         # Converts data_extract into a package for reuse
â”œâ”€â”€ requirements.txt                 # Python dependencies

ðŸ“‚ Other
â”œâ”€â”€ README.md                        # Project documentation (this file)
â””â”€â”€ .gitignore                       # Git ignore rules
```

---

## ðŸš€ Getting Started

### Prerequisites

Ensure you have the following installed:

- **Python 3.8+**
- **Pip**
- **Google Chrome**: Required for Selenium-based web scraping.
- **ChromeDriver**: Must be installed to match your Chrome version. Download it from [ChromeDriver Downloads](https://sites.google.com/chromium.org/driver/). Place the executable in a folder and update the `CHROME_DRIVER_PATH` in `config.json`.

### Installation

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/your-username/radio-song-analysis.git
   cd radio-song-analysis
   ```
2. **Create a Virtual Environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On macOS/Linux
   venv\Scripts\activate     # On Windows
   ```
3. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```
4. **Set Up Environment Variables**:
   - Copy the `.env.example` file and rename it to `.env`.
   - Fill in the required API credentials and paths in the `.env` file.

---

## ðŸ“Š How to Run

### Running the ETL Process

The ETL process scrapes real-time radio playlists, enriches them with metadata from external APIs, performs sentiment analysis on lyrics, and stores the transformed data for visualization.
Run the ETL pipeline with:

```bash
python -m data_extract.radio_music_etl
```

Start the dashboard to visualize and explore the processed data:

```bash
streamlit run dashboard/app.py
```

Open `http://localhost:8501` in your browser to access the dashboard.

---

## ðŸ™‹ Frequently Asked Questions

### â“ **1. Can I add more radio stations to scrape?**
> Yes! Extend the `radio_scraper.py` module by creating a new scraper class for the additional station.

### â“ **2. How do I customize the dashboard?**
> Modify the code in `dashboard/pages` and `dashboard/utils` to add or change visualizations.

### â“ **3. How do I update the dataset with fresh radio data?**
> Just re-run the ETL pipeline:
> ```bash
> python -m data_extract.radio_music_etl
> ```

### â“ **4. Can I export data from the dashboard?**
> Yes! The **Self-Service Exploration** page allows data filtering and downloads.

### â“ **5. What happens if a scraper encounters an error?**
> The ETL process includes logging to track and debug errors during scraping or API requests.


---

Enjoy exploring Portuguese radio trends with **Portuguese Radio Analysis**! ðŸŽ¶